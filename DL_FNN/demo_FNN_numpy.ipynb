{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79de03c4-c257-473a-8cca-da60d328c0fe",
   "metadata": {},
   "source": [
    "# Demo FNN Training in Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20a165-4ec6-4101-9a9a-c8d70df7c421",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d908accf-1522-4e0c-b67f-56510d85098b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x: (400, 2), shape of y: (400,)\n"
     ]
    }
   ],
   "source": [
    "# importing the dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "np.random.seed(seed=None)\n",
    "data = load_breast_cancer()\n",
    "x = data['data'][:400, 1:3]\n",
    "y = data['target'][:400]\n",
    "print(f\"shape of x: {x.shape}, shape of y: {y.shape}\")\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(x)\n",
    "data = np.concatenate((y.reshape(-1, 1), x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a841b-4a3e-4f76-8c27-181083a52b42",
   "metadata": {},
   "source": [
    "## Define FNN Model\n",
    "- NN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18967b6e-bbc2-4a64-9706-6250a232ba0f",
   "metadata": {},
   "source": [
    "<img src=\"images/FNN_simple.png\" alt=\"FNN\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736d7631-5c0a-459c-a57d-5c750c1a41e9",
   "metadata": {},
   "source": [
    "- Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575bfab-5515-4995-a70c-bbef2d1ea85f",
   "metadata": {},
   "source": [
    "<img src=\"images/activationfunction1.png\" alt=\"FNN\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ad57f-14e8-4673-a5f3-ce4b7519a732",
   "metadata": {},
   "source": [
    "The forward pass is\n",
    "$$\n",
    "\\boldsymbol z_1=\\sigma(W_0\\boldsymbol x\\!+\\!\\boldsymbol \\beta_0)  =\\!\\boldsymbol z_1(\\boldsymbol x;\\!\\boldsymbol\\theta),\n",
    "$$\n",
    "$$\n",
    "\\boldsymbol z_2=\\sigma(W_1\\boldsymbol z_1\\!+\\!\\boldsymbol \\beta_1)\\!=\\!\\boldsymbol z_2(\\boldsymbol x;\\!\\boldsymbol\\theta),\n",
    "$$\n",
    "$$\n",
    "\\boldsymbol z_3=\\sigma(W_2\\boldsymbol z_2\\!+\\!\\boldsymbol \\beta_2)\\!=\\!\\boldsymbol z_3(\\boldsymbol x;\\!\\boldsymbol\\theta).\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "where $\\boldsymbol z_3(\\boldsymbol x;\\!\\boldsymbol\\theta)$ is implemented as `forward(x,params)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bba7992-74b7-47e0-82ff-54fbdec9088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "def forward(x, params):\n",
    "    z_lists = []\n",
    "    for z in x:\n",
    "        z_list = [z]\n",
    "        for param in params:\n",
    "            w, b = param.values()\n",
    "            z = expit(w@z + b)\n",
    "            z_list.append(z)\n",
    "        z_lists.append(z_list)\n",
    "    return z_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a802eeee-84e0-4c31-8100-e9b30a96bef3",
   "metadata": {},
   "source": [
    "Define FNN class with the above forward pass and create FNN instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a868a2-afe2-451d-9449-2c3be458f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Define FNN model class\n",
    "class ModelNP:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "\n",
    "    def __call__(self, x):\n",
    "        z_lists = forward(x, self.params)\n",
    "        self.z_lists = z_lists\n",
    "        z_outs = [z_list[-1] for z_list in z_lists]\n",
    "        return np.array(z_outs)\n",
    "\n",
    "# Load initial parameters from a pytorch nn model\n",
    "import pickle\n",
    "with open('params_np.pickle', 'rb') as f:\n",
    "    params_np = pickle.load(f)\n",
    "\n",
    "# Create a FNN model instance\n",
    "model_np = ModelNP(params_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c169beb-f1bd-4af3-9dfb-57a46899cbce",
   "metadata": {},
   "source": [
    "## Train FNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60e590d-89ef-46cf-bc1f-d96d037a4098",
   "metadata": {},
   "source": [
    "### Loss Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f773f-18b8-4e40-998f-f7296706c427",
   "metadata": {},
   "source": [
    "#### Loss Function\n",
    "\n",
    "Use binary cross-entropy\n",
    "$$\n",
    "H(y,p)= -y\\ln p - (1-y) \\ln(1-p).\n",
    "$$\n",
    "Loss function\n",
    "$$\n",
    "J(\\boldsymbol\\theta;\\boldsymbol x,y) = H[y,\\boldsymbol z_3(\\boldsymbol x;\\!\\boldsymbol\\theta)].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c9a52d-8d84-48bc-ba23-1b4fd5cfc47a",
   "metadata": {},
   "source": [
    "#### Loss Function Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d719d47-bcc6-46fe-a45c-8bb9220dfbe1",
   "metadata": {},
   "source": [
    "Denote  \n",
    "$$D(\\boldsymbol z)\\!=\\! \\text{diag}[\\boldsymbol z\\!\\odot\\!(\\boldsymbol 1 \\!-\\!\\boldsymbol z)], \\ \\ \\ g= \\frac{\\partial J}{\\partial h_3}=z_3-y.$$\n",
    "We have\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\boldsymbol{\\beta}_2} =\\frac{\\partial J}{\\partial h_3}= g\n",
    "\\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\\n",
    "\\frac{\\partial J}{\\partial W_2}\n",
    "=\\frac{\\partial J}{\\partial h_3} \\boldsymbol{z}^T_2,\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\boldsymbol\\beta_1}\n",
    "=\\frac{\\partial J}{\\partial \\boldsymbol{h}_2}\n",
    "= D(\\boldsymbol z_2) W_2^T\\frac{\\partial J}{\\partial h_3}\n",
    "\\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\    \n",
    "\\frac{\\partial J}{\\partial W_1} \n",
    "=\\frac{\\partial J}{\\partial \\boldsymbol{h}_2} \\boldsymbol{z}_1^T,\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\boldsymbol\\beta_0}=\n",
    "\\frac{\\partial J}{\\partial \\boldsymbol{h}_1}\n",
    "\\!=\\! D(\\boldsymbol z_1)W_1^T\\frac{\\partial J}{\\partial \\boldsymbol{h}_2}\n",
    "\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \n",
    "\\frac{\\partial J}{\\partial W_0} =\\frac{\\partial J}{\\partial \\boldsymbol{h}_1}\\boldsymbol{z}_0^T.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bbd1c1-2373-48bb-ba87-b8d72643353f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center>\n",
    "<img src=\"../images/FNN_simple.PNG\" width=300 align=center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e007cf-def4-4d10-8b62-63c862bdfe38",
   "metadata": {},
   "source": [
    "The gradients are calculated iteratively as\n",
    "\n",
    "\\begin{align}\n",
    "&g \\leftarrow z_3\\!-\\!y& \\\\\n",
    "&\\text{for} \\ j:=2,1,0 \\\\\n",
    "& \\ \\ \\ \\ \\ \\ \\  \\text{Grad}({W_j}),\\text{Grad}({\\boldsymbol\\beta_j}) \\leftarrow\\! g\\boldsymbol z_j^T,\\boldsymbol  g\\\\\n",
    "& \\ \\ \\ \\ \\ \\ \\  g \\leftarrow  D(\\boldsymbol z_j){W_{j}^{*}}^T\\boldsymbol  g\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d859fdfb-6cab-4dc5-9a61-3d015f8c906f",
   "metadata": {},
   "source": [
    "which is implemented as `gradients(y,z_list,w_list)` as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8787acc7-a8e9-45e8-86cc-ebc480c833d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(y, z_list, w_list):\n",
    "    g = z_list[-1].reshape(-1, 1) - y\n",
    "    grads = []\n",
    "    for z, w in reversed(list(zip(z_list[:-1], w_list))):\n",
    "        grads.append({'w': g@z.reshape(1, -1), 'b': g})\n",
    "        g = np.diag(z*(1-z))@w.T@g\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e312084b-70b6-437d-b154-cf3971f753e9",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcef2b9-305b-4e82-ba99-1f1e0dd9237a",
   "metadata": {},
   "source": [
    "Gradient descent algorithm for optimization\n",
    "\\begin{align}\n",
    "& \\text{Input}: \\text{learning rate } \\eta,\\text{loss function } J,N_{\\text{epochs}}\\\\\n",
    "&\\text{return:}\\ \\arg\\!\\min J(\\boldsymbol\\theta)\\\\\n",
    "&\\ \\ \\ \\ \\ \\ \\ \\  \\boldsymbol \\theta \\leftarrow \\boldsymbol \\theta_{\\text{initial}}\\\\\n",
    "&\\ \\ \\ \\ \\ \\ \\ \\ \\text{for}\\ i:=1,\\dots,N_{\\text{epochs}}\\\\\n",
    "&\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\boldsymbol \\theta \\leftarrow \\boldsymbol \\theta -\\eta \\frac{\\partial }{\\partial\\boldsymbol\\theta}J(\\boldsymbol\\theta)\\\\\n",
    "&\\ \\ \\ \\ \\ \\ \\  \\ \\text{ return}\\ \\boldsymbol \\theta \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e370d207-a45b-42e4-be33-8b13d4ec4674",
   "metadata": {},
   "source": [
    "Model traing algorithm\n",
    "\\begin{align}\n",
    "&\\boldsymbol \\theta\\leftarrow \\left[W_0,W_1,W_2,\\boldsymbol\\beta_0,\\boldsymbol\\beta_1,\\boldsymbol\\beta_2\\right]_{\\text{init}}\\\\\n",
    "&\\text {for} \\text{ epoch}:=1,\\dots,N_{\\text{epochs}}\\\\\n",
    "&\\ \\  \\ \\ \\  \\ \\text {for} \\  \\{X,\\boldsymbol{y}\\}\\  := \\{X,\\boldsymbol{y}\\}_1,\\dots,\\!\\{X,\\boldsymbol{y}\\}_m \\\\\n",
    "&\\ \\  \\ \\ \\  \\ \\ \\  \\ \\ \\ \\ W_0,W_1,W_2,\\boldsymbol\\beta_0,\\boldsymbol\\beta_1,\\boldsymbol\\beta_2\\leftarrow \\boldsymbol\\theta \\\\\n",
    "&\\ \\  \\ \\ \\ \\  \\ \\  \\ \\ \\ \\ W_0^*,W_1^*,W_2^*\\leftarrow W_0,W_1,W_2 \\\\\n",
    "&\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\text {for} \\ {\\boldsymbol x },y \\  \\text{in}\\  \\{X,\\boldsymbol{y}\\} \\\\\n",
    "&\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\boldsymbol z_1,\\boldsymbol z_2,z_3 \\leftarrow \n",
    "\\boldsymbol z_1(\\boldsymbol x_i;\\!\\boldsymbol \\theta),\n",
    "\\boldsymbol z_2(\\boldsymbol x_i;\\!\\boldsymbol \\theta),  \n",
    "z_3(\\boldsymbol x_i;\\!\\boldsymbol \\theta)  \\\\\n",
    "&\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\boldsymbol g \\leftarrow z_3\\!-\\!y \\\\\n",
    "&\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\    \\text {for} \\ j:=2,1,0\\\\\n",
    "&\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\   \n",
    "\\ \\ \\ \\ \\ \\  W_j,\\boldsymbol\\beta_j  \\leftarrow W_j\\!-\\!\\frac{\\eta}{N}\\boldsymbol  g\\boldsymbol z_j^T,\\boldsymbol\\beta_j\\!-\\!\\frac{\\eta}{N}\\boldsymbol  g \\\\\n",
    "&\\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\  \\ \\ \\   \\ \\ \\  \\ \\ \\   \n",
    "\\boldsymbol  g \\leftarrow  D(\\boldsymbol z_j){W_{j}^{*}}^T\\boldsymbol  g\\\\\n",
    "&\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\   \\boldsymbol \\theta\\leftarrow \\left[W_0,W_1,W_2,\\boldsymbol\\beta_0,\\boldsymbol\\beta_1,\\boldsymbol\\beta_2\\right]\\\\\n",
    "&\\text { return }\\boldsymbol \\theta\\\n",
    "\\end{align}\n",
    "which is implemented as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b3c178-2ece-4ebf-bd41-3610cbe7bc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,accuracy:0.5675\n",
      "epoch:50,accuracy:0.5675\n",
      "epoch:100,accuracy:0.7175\n",
      "epoch:150,accuracy:0.89\n",
      "epoch:200,accuracy:0.9\n",
      "epoch:250,accuracy:0.9025\n",
      "epoch:300,accuracy:0.9025\n",
      "epoch:350,accuracy:0.9025\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self, model, lr):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.grads = None\n",
    "\n",
    "    @staticmethod\n",
    "    def gradients(y, z_lst, w_lst):\n",
    "        g = z_lst[-1].reshape(-1, 1) - y\n",
    "        g_lst = []\n",
    "        for z, w in reversed(list(zip(z_lst[:-1], w_lst))):\n",
    "            g_lst.append({'w': g @ z.reshape(1, -1), 'b': g})\n",
    "            g = np.diag(z * (1 - z)) @ w.T @ g\n",
    "        return g_lst\n",
    "\n",
    "    @staticmethod\n",
    "    def _mean_grad(grads):\n",
    "        n = len(grads)\n",
    "        w = sum([g['w'] for g in grads]) / n\n",
    "        b = sum([g['b'] for g in grads]) / n\n",
    "        return {'w': w, 'b': b[:, 0]}\n",
    "\n",
    "    @staticmethod\n",
    "    def _backward(y_vec, z_lists, w_list):\n",
    "        grads_all = []\n",
    "        for z_list, y in zip(z_lists, y_vec):\n",
    "            grads = SGD.gradients(y, z_list, w_list)\n",
    "            grads_all.append(grads)\n",
    "        grads_zip = reversed([list(x) for x in zip(*grads_all)])\n",
    "        grads_avg = [SGD._mean_grad(g) for g in grads_zip]\n",
    "        return grads_avg\n",
    "\n",
    "    def backward(self, y_vec):  # calculate gradients\n",
    "        params = self.model.params\n",
    "        w_list = [param['w'] for param in params]\n",
    "        z_lists = self.model.z_lists\n",
    "        self.grads = self._backward(y_vec, z_lists, w_list)\n",
    "        return\n",
    "\n",
    "    def step(self):  # optimize parameters with gradients\n",
    "        lr = self.lr\n",
    "        params = self.model.params\n",
    "        grads = self.grads\n",
    "        for param, grad in zip(params, grads):\n",
    "            param['w'] -= lr * grad['w']\n",
    "            param['b'] -= lr * grad['b']\n",
    "\n",
    "# minibatch data parameters\n",
    "batch_size = 50\n",
    "n_batch = int(np.ceil(data.shape[0] / batch_size))\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate, epochs = 0.1, 400\n",
    "sdg = SGD(model_np, learning_rate)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "    np.random.shuffle(data)\n",
    "    for i in range(n_batch):\n",
    "        batch = data[i * batch_size:(i + 1) * batch_size]\n",
    "        x, y = batch[:, 1:], batch[:, 0]\n",
    "        z_out = model_np(x)\n",
    "        sdg.backward(y)\n",
    "        sdg.step()\n",
    "    if epoch % 50 == 0:\n",
    "        predict = model_np(data[:, 1:]).round()\n",
    "        print(f'epoch:{epoch},accuracy:{(predict[:, 0] == data[:, 0]).mean()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
