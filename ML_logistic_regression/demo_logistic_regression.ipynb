{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31bb311c-8e68-423c-ba0f-53399d90b37f",
   "metadata": {},
   "source": [
    "# Demo Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc05998-d38f-455a-a798-81a7dbd66da4",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f897dcd5-453b-4493-8629-cae8cf9ce2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append('..')  \n",
    "from utils.ROCanalysis import calculate_roc_metrics\n",
    "\n",
    "data = load_breast_cancer()\n",
    "n_features = 4\n",
    "X = data.data[:,:n_features]          # 4 numeric features\n",
    "feature_names = data.feature_names[:n_features].tolist()\n",
    "y = data.target        # 0 = malignant, 1 = benign\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba8a72-6a88-4f8b-a13c-d3b5e391b2e8",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "### Model training with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e10026-32a4-4e89-b014-a9ffbc34b7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9298245614035088\n",
      "{'auc': 98.347, 'gini': 96.693, 'ks': 85.913}\n",
      "          feature  coefficient\n",
      "0     mean radius    29.469177\n",
      "1    mean texture    -0.986754\n",
      "2  mean perimeter   -26.738366\n",
      "3       mean area    -8.509443\n",
      "4       intercept    -0.222692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(penalty=None,max_iter=10000)  # increase max_iter to ensure convergence\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "accuracy = (y_test == y_pred).sum()/len(y_test)\n",
    "print(f\"Accuracy:{accuracy}\")\n",
    "\n",
    "proba = log_reg.predict_proba(X_test_scaled)[:,1]\n",
    "roc_df = pd.DataFrame({\n",
    "    'p': proba,\n",
    "    'y': y_test,\n",
    "    'w': np.ones(len(y_test))\n",
    "})\n",
    "print(calculate_roc_metrics(roc_df, 'p', 'y'))\n",
    "\n",
    "all_params = np.concatenate([log_reg.coef_.ravel(), log_reg.intercept_])\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": list(feature_names)+['intercept'],\n",
    "    \"coefficient\": all_params})\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804387d7-bf83-4259-a844-43259d731f8b",
   "metadata": {},
   "source": [
    "### Model training with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d634276-b939-413e-abe0-5290d7e1620b",
   "metadata": {},
   "source": [
    "Features of all samples $X\\in \\mathbb{R}^{n\\times (K+1)}$ including the all one column, labels $\\mathbf{y}\\in {\\mathbb{R}^n}$. The model output of all samples is\n",
    "\n",
    "$$\n",
    "\\mathbf{p} = f(X;\\mathbf{\\beta}).\n",
    "$$\n",
    "\n",
    "The loss is\n",
    "\n",
    "$$\n",
    "l(\\mathbf{\\beta}) = -\\frac{1}{n}\\sum_{i=1}^n \\left[y_i\\ln p_i + (1-y_i)\\ln(1-p_i)\\right].\n",
    "$$\n",
    "\n",
    "whose gradient is \n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\mathbf{\\beta}}l(\\mathbf{\\beta}) = \\frac{1}{n} X^T(\\mathbf{p}-\\mathbf{y}).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9c0261-9c6f-423e-a3b0-7bbdcbd7c361",
   "metadata": {},
   "source": [
    "In python, `beta` is a (K+1,) np.array, `X` is (n,k) np.array.  Adding a all-one column `X` to have `X_new`, (n,k+1) np.array as\n",
    "\n",
    "`X_new = np.hstack([X, np.ones((X.shape[0], 1))])`\n",
    "\n",
    "The probabity of all sample `p` (n,) np.array is calculated as\n",
    "\n",
    "`p = expit((X_new*self.beta).sum(axis=-1))`\n",
    "\n",
    "loss is calculated as\n",
    "\n",
    "`\n",
    "loss = -(y * np.log(p) + (1 - y) * np.log(1-p)).mean()\n",
    "`\n",
    "\n",
    "The gradient is calculated as\n",
    "\n",
    "`\n",
    "grad = X_new.T @ (p - y)/n\n",
    "`\n",
    "\n",
    "Model is trained as\n",
    "\n",
    "`\n",
    "logreg.beta -= lr * (X_new.T @ (p - y)/n)\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a1e6c6-02b7-4195-ad75-3d2da52a4f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "(455, 4)\n",
      "loss = 0.19915444466647877\n",
      "[ 10.73267654  -0.93639379 -16.80290975   2.00618059   0.76455038]\n",
      "loss = 0.19305564537551007\n",
      "[ 16.76921509  -0.95260907 -20.89944454  -0.36044079   0.52951171]\n",
      "loss = 0.19065515423510077\n",
      "[ 20.61657655  -0.95879707 -22.80233852  -2.64223077   0.31612982]\n",
      "loss = 0.18952695314591214\n",
      "[ 23.23463865  -0.96410799 -23.96848997  -4.35105745   0.15841819]\n",
      "loss = 0.18897535960951986\n",
      "[ 25.05998528  -0.96921722 -24.77352482  -5.56229411   0.04707063]\n",
      "loss = 0.188701339828801\n",
      "[ 26.34610846  -0.9737368  -25.35149778  -6.41010947  -0.03078427]\n",
      "loss = 0.1885638951126859\n",
      "[ 27.2573195   -0.97745373 -25.7702799   -7.00378799  -0.08529471]\n",
      "loss = 0.1884944947465408\n",
      "[ 27.90510107  -0.98036848 -26.07370514  -7.42118271  -0.12362479]\n",
      "loss = 0.18845928545561175\n",
      "[ 28.36666429  -0.98258622 -26.29306743  -7.71592904  -0.15069719]\n",
      "loss = 0.18844136137638656\n",
      "[ 28.6960716   -0.98424121 -26.45129967  -7.92484923  -0.16988984]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "class LogisticReg:\n",
    "    def __init__(self, dim, epsilon=0.00000001):\n",
    "        self.beta = np.random.rand(dim+1)\n",
    "        print(self.beta.shape)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def _with_intercept(self, X):\n",
    "        return np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "\n",
    "    def __call__(self, X):\n",
    "        X_new = self._with_intercept(X)\n",
    "        p = expit((X_new*self.beta).sum(axis=1))\n",
    "        return p\n",
    "\n",
    "    def loss(self, X, y):\n",
    "        eps = self.epsilon\n",
    "        p = np.clip(self(X), eps, 1-eps)\n",
    "        loss = -(y * np.log(p) + (1 - y) * np.log(1-p)).mean()\n",
    "        return loss\n",
    "\n",
    "    def loss_grad(self, X, y):\n",
    "        eps = self.epsilon\n",
    "        n = X.shape[0]\n",
    "        p = self(X)\n",
    "        X_new = self._with_intercept(X)\n",
    "        grad = X_new.T @ (p - y)/n # no clipping needed for bacprop\n",
    "        return grad\n",
    "\n",
    "logreg = LogisticReg(X_train.shape[1])\n",
    "print(X_train_scaled.shape)\n",
    "lr = 0.2\n",
    "for i in range(500000):\n",
    "    logreg.beta -= lr*logreg.loss_grad(X_train_scaled,y_train)\n",
    "    if (i+1)%50000==0:\n",
    "        print(f'loss = {logreg.loss(X_train_scaled,y_train)}')\n",
    "        print(logreg.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527aa28-5f33-4157-a228-3da35b1d5d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
